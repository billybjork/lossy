# Voice-First Video Companion - Project Overview

**Last Updated:** 2025-10-14
**Status:** Pre-Implementation

---

## üéØ Project Goal

Build a **voice-first browser extension** that captures natural speech while reviewing videos and automatically generates structured, time-coded feedback that gets applied to the video platform (Air, YouTube, Vimeo, etc.) via intelligent automation.

### The Problem

Video editors and reviewers waste time:
- Typing detailed feedback with precise timestamps
- Context-switching between video player and comment interface
- Losing flow state to write clear, actionable notes
- Managing feedback across multiple video versions

### The Solution

Speak naturally while watching. The system:
1. **Captures** your voice with sub-second visual feedback (emoji chips)
2. **Transcribes** speech to text locally (WASM-first, private by default)
3. **Structures** raw transcripts into clear, actionable notes (LLM)
4. **Anchors** feedback to exact video timestamps and frames
5. **Posts** automatically to the video platform (Browserbase automation)

---

## üèóÔ∏è Technology Stack

### Frontend: Browser Extension (MV3)

| Component | Technology | Why |
|-----------|-----------|-----|
| **Extension Framework** | Chrome MV3 | Side Panel API, modern security |
| **UI - Popup** | Phoenix LiveView | Real-time agent progress streaming |
| **UI - Side Panel** | Phoenix LiveView | Persistent note list with live updates |
| **UI - Overlays** | Shadow DOM + Vanilla JS | On-video ghost comments, emoji chips |
| **Voice Capture** | MediaRecorder + VAD | @ricky0123/vad-web for speech detection |
| **Local STT** | Transformers.js (Whisper) | WebGPU ‚Üí WASM ‚Üí Cloud fallback |
| **Emoji Chips** (Planned) | Text classification | Keyword/embedding-based on transcription |
| **Bundler** | Webpack 5 | Local bundling of phoenix.js |

**Technology Fallback Hierarchy:**

*Transcription (STT):*
1. **Best**: Local WASM Whisper with WebGPU acceleration (Sprint 07)
2. **Good**: Local WASM Whisper with CPU (Sprint 07)
3. **Fallback**: OpenAI Whisper API (cloud)
4. **User preference**: Settings toggle for cloud vs local

*Emoji Chips (Text-based, Planned):*
1. **Best**: Keyword-based classification (<10ms, simple)
2. **Good**: Lightweight text embeddings (~50ms, more accurate)
3. **Fallback**: Skip emoji chips (not critical for core functionality)
4. **Decision**: Based on transcription fragment availability

*Memory Considerations:*
- Local Whisper: ~300MB model + ~200MB runtime
- Emoji chips: No additional models needed (uses transcription text)

### Backend: Phoenix/Elixir

| Component | Technology | Why |
|-----------|-----------|-----|
| **Web Framework** | Phoenix 1.7 | LiveView, Channels, PubSub |
| **Real-time** | Phoenix Channels | Binary WebSocket for audio streaming |
| **UI Framework** | Phoenix LiveView | Streaming timelines, reactive updates |
| **Agent State** | GenServer + PubSub | Supervised, observable sessions |
| **Database** | PostgreSQL | Structured storage, vector embeddings |
| **Background Jobs** | Oban | Note posting queue |
| **STT (cloud)** | OpenAI Whisper API | Cloud fallback/acceleration |
| **LLM** | OpenAI GPT-4o-mini | Note structuring, intent extraction |
| **Optional Local** | Rustler NIFs | whisper.cpp/llama.cpp acceleration |

### Computer Use: Local Browser Agent

| Component | Technology | Why |
|-----------|-----------|-----|
| **Primary** | Local Chrome (dedicated profile) | Already authenticated, zero latency |
| **Automation** | Playwright via CDP | Proven reliability, platform-specific selectors |
| **AI Fallback** | Gemini 2.5 Computer Use API | Vision-based navigation for complex/unknown UIs |
| **Auth Management** | Persistent Chrome profile | Cookies/localStorage persist across sessions |
| **Fallback** | Browserbase (optional) | Cloud posting when machine offline |
| **Platform Adapters** | Existing video/timeline finders | Reusable for selector discovery |

---

## üé® Key Features

### MVP (Milestone 1)

1. **Voice Capture & Transcription**
   - Push-to-talk in popup/side panel
   - Local Whisper transcription (WASM)
   - Real-time transcript display

2. **Ghost Comments**
   - LLM structures raw speech into clear notes
   - Pinned to video timestamp
   - "Scratch that" to cancel
   - Confidence-based opacity

3. **Side Panel Note List**
   - LiveView streaming updates
   - Filter by video/category/status
   - Click to seek video timestamp

4. **Automated Posting**
   - Queue high-confidence notes
   - Local browser agent with dedicated Chrome profile
   - Real-time status updates in side panel ("Logging in...", "Posted ‚úì")
   - "Summon" feature for MFA/user intervention

### Future Enhancements

- **Text-based Emoji Chips** (sentiment/feedback visualization from transcription)
- **Semantic Search** (pgvector + text embeddings for note retrieval)
- **Multi-note Merging** (consolidate nearby similar notes)
- **Voice Commands** ("scratch that", "post all", "undo")
- **Wake Word** (continuous listening mode)
- **Collaborative** (multi-user review sessions)

---

## üìä Performance Targets

Based on blueprint and research:

| Metric | Target | Notes |
|--------|--------|-------|
| **Listening Indicator** | ‚â§100ms | Video pause + anchor display |
| **Emoji Chips (WASM)** | 300-600ms | CLIP inference on frame |
| **Emoji Chips (WebGPU)** | 50-150ms | GPU-accelerated |
| **Ghost Comment** | 0.8-1.3s | Transcription + LLM structuring |
| **Note Posting** | 5-10s | Browserbase automation |
| **Frame Capture** | 20-60ms | Grab ‚Üí scale ‚Üí WebP encode |

---

## üé≠ User Experience Flow

```
1. User clicks mic (popup or side panel)
   ‚Üì
2. Video pauses, anchor chip shows timestamp
   ‚Üì
3. User speaks: "The pacing here is too slow"
   ‚Üì
4. [300ms] Emoji chip appears: üêå (pacing)
   ‚Üì
5. [1.2s] Ghost comment appears: "Slow pacing - speed up"
   ‚Üì
6. User can:
   - Say "scratch that" ‚Üí cancels
   - Do nothing ‚Üí auto-firms after 3s
   - Click "post" ‚Üí queues for automation
   ‚Üì
7. Background: Local browser agent posts to video platform
   ‚Üì
8. Side panel updates in real-time: "üîí Logging in" ‚Üí "üì§ Posting" ‚Üí "‚úÖ Posted"
```

---

## üîí Privacy & Data Flow

### Default: Local-First

```
Browser (WASM)                Backend (Cloud)
‚îú‚îÄ‚îÄ Audio capture            ‚îú‚îÄ‚îÄ Receives: transcript text only
‚îú‚îÄ‚îÄ STT (Whisper)           ‚îú‚îÄ‚îÄ Structures with LLM
‚îú‚îÄ‚îÄ Frame capture (CLIP)    ‚îú‚îÄ‚îÄ Stores: notes, timestamps
‚îî‚îÄ‚îÄ Emoji inference         ‚îî‚îÄ‚îÄ Automation: Browserbase

‚ùå NO audio sent to cloud by default
‚úÖ Only text + metadata + embeddings
```

### Optional: Cloud Acceleration

User can opt-in to send audio for:
- Higher quality STT (OpenAI Whisper API)
- Faster processing
- Advanced features (speaker diarization)

---

## üìÅ Repository Structure

```
lossy/
‚îú‚îÄ‚îÄ docs/                          # üìö Documentation (this directory)
‚îÇ   ‚îú‚îÄ‚îÄ 01_OVERVIEW.md            # This file
‚îÇ   ‚îú‚îÄ‚îÄ 02_PRINCIPLES.md          # Development principles
‚îÇ   ‚îú‚îÄ‚îÄ 03_ARCHITECTURE.md        # System design
‚îÇ   ‚îú‚îÄ‚îÄ sprints/                  # Sprint-based roadmap
‚îÇ   ‚îú‚îÄ‚îÄ 04_LIVEVIEW_PATTERNS.md
‚îÇ   ‚îú‚îÄ‚îÄ 06_COMPUTER_USE.md        # Local-first browser automation
‚îÇ   ‚îî‚îÄ‚îÄ advanced/
‚îÇ       ‚îî‚îÄ‚îÄ BROWSERBASE_FALLBACK.md  # Optional cloud fallback
‚îÇ
‚îú‚îÄ‚îÄ lossy/                         # üî• Elixir/Phoenix application (@lossy namespace)
‚îÇ   ‚îú‚îÄ‚îÄ lib/lossy/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ accounts/             # User management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ videos/               # Video & note storage
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent/                # AgentSession GenServers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inference/            # STT/LLM routing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ automation/           # Browserbase integration
‚îÇ   ‚îú‚îÄ‚îÄ lib/lossy_web/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ channels/             # Phoenix Channels
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ live/                 # LiveView modules
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ controllers/          # REST API
‚îÇ   ‚îî‚îÄ‚îÄ priv/python/              # Existing Python agents
‚îÇ
‚îî‚îÄ‚îÄ extension/                     # üß© Browser extension (MV3)
    ‚îú‚îÄ‚îÄ src/
    ‚îÇ   ‚îú‚îÄ‚îÄ background/           # Service worker
    ‚îÇ   ‚îú‚îÄ‚îÄ content/              # Content scripts + overlays
    ‚îÇ   ‚îú‚îÄ‚îÄ sidepanel/            # Side panel (LiveView client)
    ‚îÇ   ‚îú‚îÄ‚îÄ popup/                # Popup (LiveView client)
    ‚îÇ   ‚îî‚îÄ‚îÄ shared/               # Phoenix client, utilities
    ‚îú‚îÄ‚îÄ public/
    ‚îÇ   ‚îî‚îÄ‚îÄ models/               # ONNX models (cached)
    ‚îî‚îÄ‚îÄ manifest.json
```

---

## üöÄ Success Metrics

### Technical

- ‚úÖ Sub-second feedback (emoji chips)
- ‚úÖ < 1.5s ghost comments
- ‚úÖ 95%+ transcription accuracy (clear speech)
- ‚úÖ 90%+ note posting success rate
- ‚úÖ Zero manual timestamp entry

### User Experience

- ‚úÖ Maintains flow state (no keyboard context switch)
- ‚úÖ Clear visual feedback at every step
- ‚úÖ Graceful degradation (works offline, slow networks)
- ‚úÖ Undo/cancel at any point

### Business

- ‚úÖ 10x faster feedback generation vs manual typing
- ‚úÖ 100% time-coded notes (vs ~20% manual)
- ‚úÖ Platform-agnostic (works on Air, YouTube, Vimeo, etc.)

---

## üéì Key Learnings Applied

From research and prototype:

1. **Local-first computer use** - User's authenticated browser, zero latency
2. **WASM-first transcription** - Privacy + speed (vs. cloud STT)
3. **LiveView for extension UI** - Real-time streaming perfect for agent progress
4. **Chained architecture** - OpenAI guidance, easier than realtime voice
5. **Persistent Chrome profile** - Auth persists, no credential management
6. **Platform adapters** - Reusable video/timeline element finders
7. **Phoenix Channels for binary** - Efficient audio streaming
8. **Side Panel > Popup** - Persistent UI for note list with status updates

---

## üìö References

- **Research:** Conducted 2025-10-14 (WASM inference, LiveView patterns, etc.)
- **Archived docs:** See `docs/archive/` for blueprint and earlier implementation plans

---

## ‚ö° Quick Start (After Implementation)

```bash
# Backend
cd lossy
mix deps.get
mix ecto.setup
mix phx.server

# Extension
cd extension
npm install
npm run build
# Load unpacked extension from extension/dist/
```

See `sprints/` for sprint-by-sprint implementation plan.
